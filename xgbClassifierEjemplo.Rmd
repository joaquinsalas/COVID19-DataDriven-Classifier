---
title: 'SVM classifier: Ejemplo'
author: "joaquin salas"
date: "2020.06.26"
output:
  pdf_document: default
  word_document: default
  
  #data saved in: "featureSelection.RData"
  #save(list = ls(all.names=TRUE), file = "featureSelection.RData")
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Here we develop an example of the use of the SVM classifier. I am reading the whole dataset and then select examples at random to classify.



```{r  echo=FALSE}



#import libraries
suppressMessages(library(xgboost))
#import libraries
suppressMessages(library(caret))


```


## Read the data

Dado que utilizaremos Boruta para la seleccion de caracteristicas, reducimos la base de datos mediante la siguiente estrategia. 


```{r preparacion, echo=FALSE}


#working directories
code.dir = 'E:/Documents/informs/research/2020.06.25 predicting death/code/'
setwd(code.dir)

data.dir = 'E:/Documents/informs/research/2020.06.25 predicting death/data/'

filename = paste(data.dir, "xgb_classifier.RData", sep = "")
load(file = filename)




```
## XGBoost Classifier

We built a XGBoost classifier

```{r include=FALSE}

n = 1
#predict output. This is what you want to implement in an app

clinic = data.matrix(dataset$X[n,])
y.pred = predict(xgb,clinic)
minimo = -0.49
maximo = 1.56

#xgboost only does regression. We need a procrustes normalization to make it fit in the range between zero and one
y.pred.n = (y.pred - minimo)/(maximo - minimo)

#resulting predicted value                             
print(y.pred.n)
#year when this person was born
print(2020 - (dataset$X[n,1]*sigma + mu))
print(dataset$X[n,])










```



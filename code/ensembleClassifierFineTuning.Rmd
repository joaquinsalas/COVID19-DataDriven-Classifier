---
title: 'Ensemble classifier'
author: "joaquin salas"
date: "2020.07.07"
output:
  pdf_document: default
  word_document: default
  
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Given that a patient has been confirmed positive, 
this program construct an ensemble of classifiers to infer whether the patient 
will improve or will die.
To assess the classifier, we construct ROC and precision-recall curves.



```{r  echo=FALSE}




#import libraries
suppressMessages(library(xgboost))

suppressMessages(library(caret))
suppressMessages(library(caTools))

suppressMessages(library(data.table)) # setnames

suppressMessages(require(dplyr))

suppressMessages(require(dummies)) #dummy variables
suppressMessages(require(ggplot2))
suppressMessages(require("Hmisc"))
suppressMessages(library("installr"))
suppressMessages(library(lubridate, warn.conflict = FALSE, quietly = TRUE))
suppressMessages(library(missForest)) #missForest
suppressMessages(library(matrixStats)) #colSds, standard deviation

suppressMessages(require(multiROC))
suppressMessages(require(nbpMatching))

suppressMessages(require(plotly))
suppressMessages(require(PRROC))
suppressMessages(library(pROC,verbose = TRUE )) #pROC, ROC analysis
suppressMessages(require(plyr))

suppressMessages(suppressWarnings(library(randomForest))) #for randomForest
suppressMessages(library(readr))

suppressMessages(library(stringi))

suppressMessages(library(tidyr)) #fill


suppressMessages(library(e1071))

suppressMessages(library(kernlab)) #svm

suppressMessages(require(neuralnet)) #neural networks

source("readDataSVM.R")




```


## Read the data

Dado que utilizaremos Boruta para la seleccion de caracteristicas, reducimos la base de datos mediante la siguiente estrategia. 


```{r preparacion, echo=FALSE}


#working directories
code.dir = 'E:/Documents/informs/research/2020.06.25 predicting death/code/'
setwd(code.dir)

#directories with files that  I use across many applications related to COVID
data.dir = 'E://Documents//informs//research//2020.06.25 predicting death//data//'



#files in the data.dir directory corresponding to the Health Ministery data
files.pattern = "a_*CENSO NOMINAL DF*.*"

files <- list.files(path = data.dir, pattern =  files.pattern)

#############

i = 1
for (file in files) {
  
  filename = paste(data.dir, file, sep = "")
  
  dataset = readDataSVM(filename = filename)
  
  if (i == 1) {
    data = dataset
  }
  else {
    data = rbind(data, dataset)
  }
  i = i + 1
}








covid = data[data$DIAGNOSTICO_FINAL == "COVID-19",!(names(data) %in% c("DIAGNOSTICO_FINAL"))]
condicion.medica = (covid$DESC_MOTIVO_EGRESO == "MEJORIA") | 
  (covid$DESC_MOTIVO_EGRESO == "DEFUNCION")

covid.diag = covid[condicion.medica,]

threshold.nan = 0 # the current database is full

covid.diag.pred = covid.diag[, !(names(covid.diag) %in% c("DESC_MOTIVO_EGRESO"))]

#change predictor from factor <MEJORIA, DEFUNCION> to factor <0,1>
pred = covid.diag$DESC_MOTIVO_EGRESO
pred.num = c(0,nrow=length(pred), ncol= 1)
pred.num[pred==c("MEJORIA")] = 0
pred.num[pred==c("DEFUNCION")] = 1


#pred.num = as.factor(pred.num)

too.many.nan = 
  names(covid.diag.pred)[colSums(is.na(covid.diag.pred)) > threshold.nan]


#remove variables for which there are too many missing values
covid.no.nan = covid.diag.pred[, !(names(covid.diag.pred) %in% c(too.many.nan))]




##fill missing values
covid.imp = 
  suppressMessages(suppressWarnings(missForest(covid.no.nan, verbose=FALSE)))

covid.full = covid.imp$ximp

#make sure these variables are factors
for (name in names(covid.full)) {
  if (is.factor(covid.full[,name])) {
    covid.full[,name] = droplevels(covid.full[,name])
    l = levels(droplevels(covid.full[,name]))
    if (length(l) < 2) {
      #drop factor columns with just one level
      covid.full = covid.full[,!(names(covid.full) %in% name)] 
    }
    
  }  
}




#dataset for processing
dataset = list(X = covid.full, y = pred.num) 


dim(dataset$X)


dataset$X$EDAD_ANO = as.numeric(dataset$X$EDAD_ANO)

#convert categorical variables into numeric
Xdummies = dummyVars( "~." , dataset$X)
transf = data.frame(predict(Xdummies, newdata = dataset$X))
dataset$X = transf


#normalize age
mu = mean(dataset$X$EDAD_ANO)
sigma = sd(dataset$X$EDAD_ANO)
print(mu)
print(sigma)
dataset$X$EDAD_ANO = c(scale(dataset$X$EDAD_ANO))





```
## Ensemble Classifier

We built am ensemble classifier

```{r include=FALSE}


#load classifiers
#svm.classifier
filename = paste(data.dir, "SVMClassifier2.RData", sep = "")
load(file = filename)

#rf_res
filename = paste(data.dir, "randomForestClassifier.RData", sep = "")
load(file = filename)

#xgb
filename = paste(data.dir, "xgb_classifier.RData", sep = "")
load(file = filename)



#seed for the random numbers generator
set.seed(123)


#perfom cross-validation cv.trial times


cv.trial = 1
#accumulate the results in the ROC and precision-recall curve
roc.auc = matrix(0,1, cv.trial)
pr.auc = matrix(0,1, cv.trial)


#divide subset datain half
smp.size = floor(0.5 * nrow(dataset$X))

 
  
  
  sample.ind <- createDataPartition(dataset$y, p = 0.5, list = FALSE)
  
  #construct a classifier
  
  train.x = data.matrix(dataset$X[sample.ind,])
  #train.y = as.numeric(dataset$y[sample.ind])-1
  train.y = dataset$y[sample.ind]
  
  test.x = data.matrix(dataset$X[-sample.ind,])
  #test.y = as.numeric(dataset$y[-sample.ind])-1
  test.y = dataset$y[-sample.ind]
  
  #predict xgb output. This is what you want to implement in an app
  y.pred.xgb = predict(xgb, train.x)
  r.minimo = -0.49
  r.maximo = 1.56
  y.xgb = (y.pred.xgb - r.minimo)/(r.maximo - r.minimo)
  
  y.svm = predict(svm.classifier, train.x,type = "prob")
  
  y.rf = predict(rf_res, train.x,type = "prob")
  
  train = data.frame(y = train.y, xgb = y.xgb, svm = y.svm[,2], rf = y.rf[,2])
  
  for (n in seq(0,10)) {
    
    print(n)
    nn=neuralnet(y~. ,data=train, hidden=n,act.fct = "logistic",
                 linear.output = FALSE)
    
    
    #test
    #predict xgb output. This is what you want to implement in an app
    y.pred.xgb = predict(xgb, test.x)
    r.minimo = -0.49
    r.maximo = 1.56
    y.xgb = (y.pred.xgb - r.minimo)/(r.maximo - r.minimo)
    
    y.svm = predict(svm.classifier, test.x,type = "prob")
    
    y.rf = predict(rf_res, test.x,type = "prob")
    
    
    test = data.frame(xgb = y.xgb, svm = y.svm[,2], rf = y.rf[,2])
    
    
    ## Prediction using neural network
    pred=predict(nn,test)
    
    
    #performance results
    roc<-roc.curve(scores.class0 = pred,
                   weights.class0 = test.y, curve= TRUE)
    pr<-pr.curve(scores.class0 =  pred,
                 weights.class0 = test.y, curve= TRUE)
    
    
   
    
    
    #save results for each classifier
    
    
    print(roc$auc)
    print(pr$auc.integral)

  }
 
  
  nn=neuralnet(y~. ,data=train, hidden=0, 
               #act.fct = "logistic",
                 linear.output = FALSE)








filename = paste(data.dir, "nn.RData", sep = "")
save(list = ls(all.names=TRUE), file = filename)

load(filename)

lista = c("nn")
filename = paste(data.dir, "nn_classifier.RData", sep = "")
save(list = lista, file = filename)



```



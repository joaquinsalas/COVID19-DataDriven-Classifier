---
title: 'SVM Classifier'
author: "Joaquin Salas"
date: "2020.08.08"
output:
  pdf_document: default
  word_document: default
  
  #data saved in: "featureSelection.RData"
  #save(list = ls(all.names=TRUE), file = "featureSelection.RData")
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This program construct a classifier to discriminate between those that live and those that die.
Starting with a dataset, it trains a classifier and evaluate it using ROC and precision-recall curves.
The program divides the dataset in half for training and half for testing. It does so $n$-times. Each time, it analyses the performance. The output files include

* *classifier*\_*entity*\_ROC\_*iteration*.csv
It includes the points in the ROC curve

* *classifier*\_*entity*\_PR\_*iteration*.csv
It includes the points in the precision-recall curve

*classifier* is an acronym where *RF*, *NN*, *SVM*, *XGB* stand for random forest, neural network, support vector machine and extreme gradient boosting. Entity is a two letters word referencing the state, e.g., DF, QT, SL stand for Mexico City, Queretaro and Sinaloa.

*iteration* stands for the number of iteration where the performance was evaluated.


```{r  echo=FALSE}




#import libraries
suppressMessages(library(caret))
suppressMessages(library(caTools))

suppressMessages(library(data.table)) # setnames

suppressMessages(require(dplyr))

suppressMessages(require(dummies)) #dummy variables
suppressMessages(require(ggplot2))
suppressMessages(require("Hmisc"))
suppressMessages(library("installr"))
suppressMessages(library(lubridate, warn.conflict = FALSE, quietly = TRUE))
suppressMessages(library(missForest)) #missForest
suppressMessages(library(matrixStats)) #colSds, standard deviation

suppressMessages(require(multiROC))
suppressMessages(require(nbpMatching))

suppressMessages(require(plotly))
suppressMessages(require(PRROC))
suppressMessages(library(pROC,verbose = TRUE )) #pROC, ROC analysis
suppressMessages(require(plyr))

suppressMessages(suppressWarnings(library(randomForest))) #for randomForest
suppressMessages(library(readr))

suppressMessages(library(stringi))

suppressMessages(library(tidyr)) #fill


suppressMessages(library(e1071))

suppressMessages(library(kernlab)) #svm



#working directories
code.dir = 'E:/Documents/informs/research/2020.06.25 predicting death/code/'
setwd(code.dir)

#directories with files that  I use across many applications related to COVID
data.dir = 'E://Documents//informs//research//2020.06.25 predicting death//data//'


#filename = paste(code.dir,"readDataFeatures.R", sep = "")
#source(filename)

filename = paste(code.dir,"preprocessData.R", sep = "")
source(filename)

#filename = paste(code.dir,"balanceData.R", sep = "")
#source(filename)


#prefix = "QT"
#file.root = "20200802 CENSO NOMINAL "

#prefix = "SL"
#file.root = "20200730  CENSO NOMINAL "

prefix = "DF"
file.root = "20200626 CENSO NOMINAL "

#acquire and preprocess the data to construct a classifier
dataset = preprocessData(prefix, file.root, data.dir)


covid.full = dataset$X


ndata = data.frame(dataset$X, y = factor(dataset$y))

#make syntactically valid names
names(ndata) = make.names(names(ndata))

names(ndata) [names(ndata) == "pred.num"] = "y"

#otherwise there will be an error during train
levels(ndata$y)[1]<-"positive"
levels(ndata$y)[2]<-"negative"


#seed for the random numbers generator
set.seed(123)
#123 fails at the seventh iteration!


#perfom cross-validation cv.trial times


cv.trial = 30
#accumulate the results in the ROC and precision-recall curve
roc.auc = matrix(0,1, cv.trial)
pr.auc = matrix(0,1, cv.trial)


#divide subset datain half
smp.size = floor(0.5 * nrow(ndata))


#cross-validation iterations
for (trial in seq(1,cv.trial)) {
  #for (trial in seq(1,1)) {  
  
  print(trial)
  
  
  
  ndata.ind <- createDataPartition(ndata$y, p = 0.5, list = FALSE)
  
  #construct a classifier
  X = ndata[ndata.ind,]
  
  train.data = balanceDataFactor(X)
  
  
  #there is an issue with train
  #https://github.com/topepo/caret/issues/809
  svm.classifier <- suppressWarnings(train(
    y ~., data = train.data, method = "svmRadial",
    trControl = trainControl("cv", number = 10, classProbs = TRUE),
    preProcess = c("center","scale"),
    tuneLength = 10
  ))
  
  #ksvm.classifier = ksvm(y ~., data = ndata[ndata.ind,])
  
  
  #construct a classifier
  X = ndata[-ndata.ind,]
  
  test.data = balanceDataFactor(X)
 
  
  
  #predict output. This is what you want to implement in an app
  y_pred = predict(svm.classifier,test.data,type = "prob")
  # y_pred = predict(svm.classifier,covid.full[-ndata.ind,],type = "prob")
  
  #init an array with zeros
  ground.truth = array(0, dim = dim(y_pred)[1] )
  test.set = test.data$y=="negative"
  ground.truth[test.set] = 1
  
  
  #performance results
  roc<-roc.curve(scores.class0 = y_pred[,2],
                 weights.class0 = ground.truth, curve= TRUE)
  pr<-pr.curve(scores.class0 =  y_pred[,2],
               weights.class0 = ground.truth, curve= TRUE)
  
  
  #save results for analysis
  roc.auc[ trial] = roc$auc
  pr.auc[ trial] = pr$auc.integral
  
  #save results for each classifier
  filename = sprintf("../data/svm_%s_roc_%03d.csv", prefix, trial)
  write.csv(roc$curve,filename)
  
  filename = sprintf("../data/svm_%s_pr_%03d.csv", prefix,trial)
  write.csv(pr$curve,filename)
  
  
  print(roc$auc)
  print(pr$auc.integral)
  
}




mu = dataset$mu
sigma = dataset$sigma


lista = c("svm.classifier", "sigma", "mu")
filename = paste(data.dir, "SVMClassifier_", prefix, ".RData", sep = "")
save(list = lista, file = filename)
#load(file = filename)

```



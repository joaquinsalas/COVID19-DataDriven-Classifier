---
title: 'Neural Network Classifier'
author: "Joaquin Salas"
date: "2020.08.04"
output:
  pdf_document: default
  word_document: default
  
  #data saved in: "featureSelection.RData"
  #save(list = ls(all.names=TRUE), file = "featureSelection.RData")
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
This program construct a classifier to discriminate between those that live and those that die.
Starting with a dataset, it trains a classifier and evaluate it using ROC and precision-recall curves.
The program divides the dataset in half for training and half for testing. It does so $n$-times. Each time, it analyses the performance. The output files include

* *classifier*\_*entity*\_ROC\_*iteration*.csv
It includes the points in the ROC curve

* *classifier*\_*entity*\_PR\_*iteration*.csv
It includes the points in the precision-recall curve

*classifier* is an acronym where *RF*, *NN*, *SVM*, *XGB* stand for random forest, neural network, support vector machine and extreme gradient boosting. Entity is a two letters word referencing the state, e.g., DF, QT, SL stand for Mexico City, Queretaro and Sinaloa.

*iteration* stands for the number of iteration where the performance was evaluated.


```{r  echo=FALSE}




#import libraries
suppressMessages(library(caret))
suppressMessages(library(caTools))

suppressMessages(library(data.table)) # setnames

suppressMessages(require(dplyr))

suppressMessages(require(dummies)) #dummy variables
suppressMessages(require(ggplot2))
suppressMessages(require("Hmisc"))
suppressMessages(library("installr"))
suppressMessages(library(lubridate, warn.conflict = FALSE, quietly = TRUE))
suppressMessages(library(missForest)) #missForest
suppressMessages(library(matrixStats)) #colSds, standard deviation

suppressMessages(require(multiROC))
suppressMessages(require(nbpMatching))

suppressMessages(require(plotly))
suppressMessages(require(PRROC))
suppressMessages(library(pROC,verbose = TRUE )) #pROC, ROC analysis
suppressMessages(require(plyr))

suppressMessages(suppressWarnings(library(randomForest))) #for randomForest
suppressMessages(library(readr))

suppressMessages(library(stringi))


suppressMessages(library(tidyr)) #fill
suppressMessages(require(neuralnet)) #neural networks



#working directories
code.dir = 'E:/Documents/informs/research/2020.06.25 predicting death/code/'
setwd(code.dir)

#directories with files that  I use across many applications related to COVID
data.dir = 'E://Documents//informs//research//2020.06.25 predicting death//data//'



#filename = paste(code.dir,"readDataFeatures.R", sep = "")
#source(filename)

filename = paste(code.dir,"preprocessData.R", sep = "")
source(filename)

#filename = paste(code.dir,"balanceData.R", sep = "")
#source(filename)



#prefix = "QT"
#file.root = "20200802 CENSO NOMINAL "

#prefix = "SL"
#file.root = "20200730  CENSO NOMINAL "

prefix = "DF"
file.root = "20200626 CENSO NOMINAL "

#acquire and preprocess the data to construct a classifier
dataset = preprocessData(prefix, file.root, data.dir)


  
#seed for the random numbers generator
set.seed(123)


#perfom cross-validation cv.trial times


cv.trial = 30
#accumulate the results in the ROC and precision-recall curve
roc.auc = matrix(0,1, cv.trial)
pr.auc = matrix(0,1, cv.trial)


#divide subset datain half
smp.size = floor(0.5 * nrow(dataset$X))



for (trial in seq(1,cv.trial)) {
  
  print(trial)
  
  sample.ind <- createDataPartition(dataset$y, p = 0.5, list = FALSE)
  
  #construct a classifier
  
  train.x = data.matrix(dataset$X[sample.ind,])
  #train.y = as.numeric(dataset$y[sample.ind])-1
  train.y = dataset$y[sample.ind]
  
  test.x = data.matrix(dataset$X[-sample.ind,])
  #test.y = as.numeric(dataset$y[-sample.ind])-1
  test.y = dataset$y[-sample.ind]
  
  
  result = balanceData(train.x, train.y)
  train.x = result$X
  train.y = result$y
  
  
  
  train = data.frame(train.x,y = train.y)
  
  
  #construct a classifier
  nn.classifier=neuralnet(y~. ,data=train, hidden=c(1),act.fct = "logistic",
                linear.output = FALSE, err.fct = "ce", threshold = 0.1)
  
  
  result = balanceData(test.x, test.y)
  test.x = result$X
  test.y = result$y
  
  #predict output. This is what you want to implement in an app
  nn.pred = predict(nn.classifier,test.x,type = "prob")
  
  #init an array with zeros
  ground.truth = array(0, dim = length(nn.pred) )
  ground.truth[test.y==1] = 1
  
  
  #performance results
  roc<-roc.curve(scores.class0 = nn.pred, weights.class0 = ground.truth, curve= TRUE)
  pr<-pr.curve(scores.class0 =  nn.pred, weights.class0 = ground.truth, curve= TRUE)
  
  
  #save results for analysis
  roc.auc[trial] = roc$auc
  pr.auc[trial] = pr$auc.integral
  
  
  #save results for each classifier
  filename = sprintf("../data/NN_%s_roc_%03d.csv", prefix, trial)
  write.csv(roc$curve,filename)
  
  filename = sprintf("../data/NN_%s_pr_%03d.csv", prefix, trial)
  write.csv(pr$curve,filename)
  
  
  print(roc$auc)
  print(pr$auc.integral)
  
}


mu = dataset$mu
sigma = dataset$sigma


lista = c("nn.classifier", "sigma", "mu")
filename = paste(data.dir, "nnClassifier_",prefix,".RData", sep = "")
save(list = lista, file = filename)


load(file = filename)

```


